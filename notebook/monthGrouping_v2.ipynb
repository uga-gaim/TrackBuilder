{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/1091481605.py:1: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_jan = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201901.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/1091481605.py:2: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_feb = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201902.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/1091481605.py:3: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_mar = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201903.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/1091481605.py:4: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_apr = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201904.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/1091481605.py:5: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_may = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201905.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/1091481605.py:6: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_jun = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201906.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "df_jan = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201901.csv', sep=';')\n",
    "df_feb = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201902.csv', sep=';')\n",
    "df_mar = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201903.csv', sep=';')\n",
    "df_apr = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201904.csv', sep=';')\n",
    "df_may = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201905.csv', sep=';')\n",
    "df_jun = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201906.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/2925148990.py:1: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_jul = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201907.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/2925148990.py:2: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_aug = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201908.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/2925148990.py:3: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_sep = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201909.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/2925148990.py:4: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_oct = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201910.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/2925148990.py:5: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_nov = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201911.csv', sep=';')\n",
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/2925148990.py:6: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dec = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201912.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "df_jul = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201907.csv', sep=';')\n",
    "df_aug = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201908.csv', sep=';')\n",
    "df_sep = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201909.csv', sep=';')\n",
    "df_oct = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201910.csv', sep=';')\n",
    "df_nov = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201911.csv', sep=';')\n",
    "df_dec = pd.read_csv('/Users/willponczak/Desktop/QC2025/data/astd/complete_data/2019/ASTD_area_level3_201912.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [df_jan, df_feb, df_mar, df_apr, df_may, df_jun, \n",
    "              df_jul, df_aug, df_sep, df_oct, df_nov, df_dec, df_jan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18385487, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUPING EVERY 2 CONSECUTIVE MONTHS TOGETHER\n",
    "\n",
    "def data_prep(\n",
    "        df_prev: pd.DataFrame,\n",
    "        df_next: pd.DataFrame,\n",
    "        n_days_prev_month: int,\n",
    "        n_days_next_month: int\n",
    "):\n",
    "    # Convert the date_time_utc column from string to datetime object\n",
    "    df_prev['date_time_utc'] = pd.to_datetime(df_prev['date_time_utc'])\n",
    "    df_next['date_time_utc'] = pd.to_datetime(df_next['date_time_utc'])\n",
    "\n",
    "    # Extract day from datetime and get last/first unique days\n",
    "    last_days = sorted(df_prev['date_time_utc'].dt.date.unique())[-n_days_prev_month:]\n",
    "    first_days = sorted(df_next['date_time_utc'].dt.date.unique())[:n_days_next_month]\n",
    "\n",
    "    # Filter rows where date matches the selected days\n",
    "    df_last_days = df_prev[df_prev['date_time_utc'].dt.date.isin(last_days)]\n",
    "    df_first_days = df_next[df_next['date_time_utc'].dt.date.isin(first_days)]\n",
    "\n",
    "    # Combine the rows\n",
    "    df_output = pd.concat([df_last_days, df_first_days])\n",
    "\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP ALL 2 MONTH BLOCKS TOGETHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_processed = []\n",
    "\n",
    "# I think this needs to be fixed to circle back to the first day of Jan\n",
    "# Right now I believe it starts at the end of Jan and ends at the beginning of dec\n",
    "# And those 2 never connect in the method.\n",
    "for i in range(len(file_names) - 1):\n",
    "    df_prev = file_names[i]\n",
    "    df_next = file_names[i + 1]\n",
    "\n",
    "    # You need to decide how many days to take from each month; here as example, use 3 days each\n",
    "    processed_df = data_prep(df_prev, df_next, n_days_prev_month=1, n_days_next_month=1)\n",
    "    dfs_processed.append(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(dfs_processed, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15110732, 26)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shipid</th>\n",
       "      <th>date_time_utc</th>\n",
       "      <th>flagname</th>\n",
       "      <th>iceclass</th>\n",
       "      <th>astd_cat</th>\n",
       "      <th>sizegroup_gt</th>\n",
       "      <th>fuelquality</th>\n",
       "      <th>fuelcons</th>\n",
       "      <th>co</th>\n",
       "      <th>co2</th>\n",
       "      <th>...</th>\n",
       "      <th>blackcarbon</th>\n",
       "      <th>organiccarbon</th>\n",
       "      <th>oilbilgewater</th>\n",
       "      <th>blackwater</th>\n",
       "      <th>greywater</th>\n",
       "      <th>garbage</th>\n",
       "      <th>dist_nextpoint</th>\n",
       "      <th>sec_nextpoint</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134819</th>\n",
       "      <td>485</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.535610</td>\n",
       "      <td>369</td>\n",
       "      <td>15.072133</td>\n",
       "      <td>68.913230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169605</th>\n",
       "      <td>641</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.087459</td>\n",
       "      <td>362</td>\n",
       "      <td>29.090300</td>\n",
       "      <td>70.857620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211080</th>\n",
       "      <td>832</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573281</td>\n",
       "      <td>361</td>\n",
       "      <td>15.682477</td>\n",
       "      <td>69.141160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274785</th>\n",
       "      <td>1642</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>FS Ice Class 1C</td>\n",
       "      <td>Fishing vessels</td>\n",
       "      <td>&lt; 1000 GT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.005946</td>\n",
       "      <td>...</td>\n",
       "      <td>3.376000e-07</td>\n",
       "      <td>1.140500e-06</td>\n",
       "      <td>4.400000e-09</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.019840</td>\n",
       "      <td>246</td>\n",
       "      <td>-24.954306</td>\n",
       "      <td>65.126495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337529</th>\n",
       "      <td>2123</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General cargo ships</td>\n",
       "      <td>&lt; 1000 GT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>...</td>\n",
       "      <td>3.676000e-07</td>\n",
       "      <td>1.241800e-06</td>\n",
       "      <td>6.600000e-09</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.345787</td>\n",
       "      <td>370</td>\n",
       "      <td>11.281121</td>\n",
       "      <td>64.858740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430033</th>\n",
       "      <td>7541</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>FS Ice Class 1B</td>\n",
       "      <td>Refrigerated cargo ships</td>\n",
       "      <td>1000 - 4999 GT</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040549</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.128540</td>\n",
       "      <td>...</td>\n",
       "      <td>7.298800e-06</td>\n",
       "      <td>2.465380e-05</td>\n",
       "      <td>2.660000e-08</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2255.288300</td>\n",
       "      <td>361</td>\n",
       "      <td>7.432227</td>\n",
       "      <td>63.850224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545886</th>\n",
       "      <td>8353</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>FS Ice Class 1A</td>\n",
       "      <td>General cargo ships</td>\n",
       "      <td>1000 - 4999 GT</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>...</td>\n",
       "      <td>2.865000e-07</td>\n",
       "      <td>9.677000e-07</td>\n",
       "      <td>1.330000e-08</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.657768</td>\n",
       "      <td>180</td>\n",
       "      <td>24.519463</td>\n",
       "      <td>65.663055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        shipid date_time_utc    flagname         iceclass  \\\n",
       "134819     485    2019-01-31         NaN              NaN   \n",
       "169605     641    2019-01-31      Norway              NaN   \n",
       "211080     832    2019-01-31         NaN              NaN   \n",
       "274785    1642    2019-01-31     Iceland  FS Ice Class 1C   \n",
       "337529    2123    2019-01-31      Norway              NaN   \n",
       "430033    7541    2019-01-31     Bahamas  FS Ice Class 1B   \n",
       "545886    8353    2019-01-31  Luxembourg  FS Ice Class 1A   \n",
       "\n",
       "                        astd_cat    sizegroup_gt  fuelquality  fuelcons  \\\n",
       "134819                   Unknown             NaN            0       NaN   \n",
       "169605                   Unknown             NaN            0       NaN   \n",
       "211080                   Unknown             NaN            0       NaN   \n",
       "274785           Fishing vessels       < 1000 GT            0  0.001876   \n",
       "337529       General cargo ships       < 1000 GT            0  0.002042   \n",
       "430033  Refrigerated cargo ships  1000 - 4999 GT            3  0.040549   \n",
       "545886       General cargo ships  1000 - 4999 GT            1  0.001592   \n",
       "\n",
       "              co       co2  ...   blackcarbon  organiccarbon  oilbilgewater  \\\n",
       "134819       NaN       NaN  ...           NaN            NaN            NaN   \n",
       "169605       NaN       NaN  ...           NaN            NaN            NaN   \n",
       "211080       NaN       NaN  ...           NaN            NaN            NaN   \n",
       "274785  0.000014  0.005946  ...  3.376000e-07   1.140500e-06   4.400000e-09   \n",
       "337529  0.000015  0.006474  ...  3.676000e-07   1.241800e-06   6.600000e-09   \n",
       "430033  0.000300  0.128540  ...  7.298800e-06   2.465380e-05   2.660000e-08   \n",
       "545886  0.000012  0.005045  ...  2.865000e-07   9.677000e-07   1.330000e-08   \n",
       "\n",
       "        blackwater  greywater  garbage  dist_nextpoint  sec_nextpoint  \\\n",
       "134819         NaN        NaN      NaN        2.535610            369   \n",
       "169605         NaN        NaN      NaN        1.087459            362   \n",
       "211080         NaN        NaN      NaN        0.573281            361   \n",
       "274785    0.000797   0.002619      0.0      255.019840            246   \n",
       "337529    0.001199   0.003940      0.0        3.345787            370   \n",
       "430033    0.001149   0.008503      0.0     2255.288300            361   \n",
       "545886    0.000573   0.004240      0.0        1.657768            180   \n",
       "\n",
       "        longitude   latitude  \n",
       "134819  15.072133  68.913230  \n",
       "169605  29.090300  70.857620  \n",
       "211080  15.682477  69.141160  \n",
       "274785 -24.954306  65.126495  \n",
       "337529  11.281121  64.858740  \n",
       "430033   7.432227  63.850224  \n",
       "545886  24.519463  65.663055  \n",
       "\n",
       "[7 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[(df_all['date_time_utc'] == pd.to_datetime('2019-01-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['date_time_utc'] = pd.to_datetime(df_all['date_time_utc'])\n",
    "\n",
    "df_all['year'] = df_all['date_time_utc'].dt.year\n",
    "df_all['month'] = df_all['date_time_utc'].dt.month\n",
    "df_all['day'] = df_all['date_time_utc'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/bphw52wd7fngbyw4fdd0280h0000gp/T/ipykernel_6600/236622090.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  month_check = df_all.groupby(['year', 'month']).apply(verify_days)\n"
     ]
    }
   ],
   "source": [
    "def verify_days(group):\n",
    "    days = group['day']\n",
    "    has_first = 1 in days.values\n",
    "    has_last = days.max() in days.values\n",
    "    return pd.Series({'has_first': has_first, 'has_last': has_last})\n",
    "\n",
    "\n",
    "month_check = df_all.groupby(['year', 'month']).apply(verify_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            has_first  has_last\n",
      "year month                     \n",
      "2019 1           True      True\n",
      "     2           True      True\n",
      "     3           True      True\n",
      "     4           True      True\n",
      "     5           True      True\n",
      "     6           True      True\n",
      "     7           True      True\n",
      "     8           True      True\n",
      "     9           True      True\n",
      "     10          True      True\n",
      "     11          True      True\n",
      "     12          True      True\n"
     ]
    }
   ],
   "source": [
    "print(month_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('all_months_1day.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
